{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (2.0.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.33.6)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.1.7)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.16.4)\n",
      "Requirement already satisfied: h5py in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (41.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from rsa>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: sklearn in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from sklearn) (0.21.3)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.16.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install sklearn\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# while(True):\n",
    "#     cap = cv2.VideoCapture(0)\n",
    "#     # Capture frame-by-frame\n",
    "#     ret, frame = cap.read()\n",
    "# \n",
    "#     # Our operations on the frame come here\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "# \n",
    "#     # Display the resulting frame\n",
    "#     cv2.imshow('frame',gray)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "# \n",
    "# # When everything done, release the capture\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR1 = \"Rock-Paper-Scissors/train\"\n",
    "CATEGORIES = [\"paper\", \"rock\", \"scissors\"]\n",
    "IMG_WIDTH = 75\n",
    "IMG_HEIGHT = 50\n",
    "BATCH_SIZE = 150\n",
    "\n",
    "def load_data(data_dir1, CATEGORIES, img_width, img_height):\n",
    "    X = []\n",
    "    y = []\n",
    "    index = 0\n",
    "\n",
    "    for category in CATEGORIES:\n",
    "        one_hot = np.zeros(len(CATEGORIES))  # to encode the class as a one hot vector\n",
    "        one_hot[index] = 1\n",
    "        path = os.path.join(data_dir1, category)\n",
    "        index += 1\n",
    "\n",
    "        for img in os.listdir(path): # get all images in the path\n",
    "            img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "            img_arr = cv2.resize(img_arr, (img_width, img_height))\n",
    "            img_arr = np.asarray(img_arr)\n",
    "            X.append(img_arr)\n",
    "            y.append(one_hot)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = load_data(DATA_DIR1, CATEGORIES, IMG_WIDTH, IMG_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR2 = \"rockpaperscissors\"\n",
    "CATEGORIES = [\"paper\", \"rock\", \"scissors\"]\n",
    "IMG_WIDTH = 75\n",
    "IMG_HEIGHT = 50\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "def load_data(data_dir2, CATEGORIES, img_width, img_height):\n",
    "    X = []\n",
    "    y = []\n",
    "    index = 0\n",
    "    \n",
    "    for category in CATEGORIES:\n",
    "        one_hot = np.zeros(len(CATEGORIES))  # to encode the class as a one hot vector\n",
    "        one_hot[index] = 1\n",
    "        path = os.path.join(data_dir2, category)\n",
    "        index += 1\n",
    "        \n",
    "        for img in os.listdir(path): # get all images in the path\n",
    "            img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "            img_arr = cv2.resize(img_arr, (img_width, img_height))\n",
    "            img_arr = np.asarray(img_arr)\n",
    "            X.append(img_arr)\n",
    "            y.append(one_hot)\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "X2, y2 = load_data(DATA_DIR2, CATEGORIES, IMG_WIDTH, IMG_HEIGHT)\n",
    "X += X2\n",
    "y+= y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (3766, 75, 50, 1)\n",
      "3766 train samples\n",
      "942 test samples\n"
     ]
    }
   ],
   "source": [
    "# Divide our data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "\n",
    "# Normalize our data\n",
    "X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)\n",
    "\n",
    "# reshape the data into a 4D tensor - (sample_number, x_img_size, y_img_size, num_channels)\n",
    "# because we are using greyscale, we only have a single channel - RGB colour images would have 3\n",
    "X_train = X_train.reshape(X_train.shape[0], IMG_WIDTH, IMG_HEIGHT, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], IMG_WIDTH, IMG_HEIGHT, 1)\n",
    "input_shape = (IMG_WIDTH, IMG_HEIGHT, 1)\n",
    "\n",
    "# convert the data to the right type\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# X_train /= 50\n",
    "# X_test /= 50\n",
    "print('x_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3766 samples, validate on 942 samples\n",
      "Epoch 1/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 1.0989 - accuracy: 0.3380 - val_loss: 1.0979 - val_accuracy: 0.3652\n",
      "Epoch 2/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 1.0966 - accuracy: 0.3603 - val_loss: 1.0948 - val_accuracy: 0.3758\n",
      "Epoch 3/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 1.0950 - accuracy: 0.3712 - val_loss: 1.0926 - val_accuracy: 0.4236\n",
      "Epoch 4/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 1.0932 - accuracy: 0.3885 - val_loss: 1.0905 - val_accuracy: 0.4926\n",
      "Epoch 5/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 1.0904 - accuracy: 0.4079 - val_loss: 1.0889 - val_accuracy: 0.4469\n",
      "Epoch 6/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 1.0880 - accuracy: 0.4047 - val_loss: 1.0870 - val_accuracy: 0.3652\n",
      "Epoch 7/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 1.0854 - accuracy: 0.4251 - val_loss: 1.0837 - val_accuracy: 0.4735\n",
      "Epoch 8/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 1.0816 - accuracy: 0.4259 - val_loss: 1.0789 - val_accuracy: 0.5085\n",
      "Epoch 9/100\n",
      "3766/3766 [==============================] - 32s 8ms/sample - loss: 1.0764 - accuracy: 0.4373 - val_loss: 1.0739 - val_accuracy: 0.5180\n",
      "Epoch 10/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 1.0736 - accuracy: 0.4506 - val_loss: 1.0695 - val_accuracy: 0.5202\n",
      "Epoch 11/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 1.0673 - accuracy: 0.4599 - val_loss: 1.0637 - val_accuracy: 0.5138\n",
      "Epoch 12/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 1.0614 - accuracy: 0.4729 - val_loss: 1.0575 - val_accuracy: 0.5234\n",
      "Epoch 13/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 1.0553 - accuracy: 0.4881 - val_loss: 1.0492 - val_accuracy: 0.5117\n",
      "Epoch 14/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 1.0462 - accuracy: 0.4963 - val_loss: 1.0408 - val_accuracy: 0.5106\n",
      "Epoch 15/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 1.0337 - accuracy: 0.5167 - val_loss: 1.0257 - val_accuracy: 0.6104\n",
      "Epoch 16/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 1.0204 - accuracy: 0.5303 - val_loss: 1.0149 - val_accuracy: 0.5849\n",
      "Epoch 17/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 1.0056 - accuracy: 0.5380 - val_loss: 1.0013 - val_accuracy: 0.5372\n",
      "Epoch 18/100\n",
      "3766/3766 [==============================] - 34s 9ms/sample - loss: 0.9892 - accuracy: 0.5571 - val_loss: 0.9736 - val_accuracy: 0.6178\n",
      "Epoch 19/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.9639 - accuracy: 0.5773 - val_loss: 0.9529 - val_accuracy: 0.6539\n",
      "Epoch 20/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.9401 - accuracy: 0.5890 - val_loss: 0.9264 - val_accuracy: 0.6433\n",
      "Epoch 21/100\n",
      "3766/3766 [==============================] - 32s 8ms/sample - loss: 0.9154 - accuracy: 0.6182 - val_loss: 0.9090 - val_accuracy: 0.6115\n",
      "Epoch 22/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.8895 - accuracy: 0.6251 - val_loss: 0.8761 - val_accuracy: 0.6359\n",
      "Epoch 23/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.8602 - accuracy: 0.6423 - val_loss: 0.8340 - val_accuracy: 0.6921\n",
      "Epoch 24/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.8415 - accuracy: 0.6601 - val_loss: 0.8487 - val_accuracy: 0.6582\n",
      "Epoch 25/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.8001 - accuracy: 0.6784 - val_loss: 0.7647 - val_accuracy: 0.7197\n",
      "Epoch 26/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.7749 - accuracy: 0.6885 - val_loss: 0.7544 - val_accuracy: 0.7123\n",
      "Epoch 27/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.7476 - accuracy: 0.7013 - val_loss: 0.7082 - val_accuracy: 0.7527\n",
      "Epoch 28/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.7136 - accuracy: 0.7270 - val_loss: 0.6696 - val_accuracy: 0.7473\n",
      "Epoch 29/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.6836 - accuracy: 0.7369 - val_loss: 0.6303 - val_accuracy: 0.7824\n",
      "Epoch 30/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.6660 - accuracy: 0.7472 - val_loss: 0.6028 - val_accuracy: 0.7813\n",
      "Epoch 31/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.6373 - accuracy: 0.7549 - val_loss: 0.5705 - val_accuracy: 0.8132\n",
      "Epoch 32/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.6038 - accuracy: 0.7751 - val_loss: 0.5358 - val_accuracy: 0.8206\n",
      "Epoch 33/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.5844 - accuracy: 0.7770 - val_loss: 0.5665 - val_accuracy: 0.7845\n",
      "Epoch 34/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.5662 - accuracy: 0.7817 - val_loss: 0.4886 - val_accuracy: 0.8567\n",
      "Epoch 35/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.5255 - accuracy: 0.8101 - val_loss: 0.4842 - val_accuracy: 0.8365\n",
      "Epoch 36/100\n",
      "3766/3766 [==============================] - 34s 9ms/sample - loss: 0.5139 - accuracy: 0.8091 - val_loss: 0.4465 - val_accuracy: 0.8577\n",
      "Epoch 37/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.4802 - accuracy: 0.8287 - val_loss: 0.4255 - val_accuracy: 0.8705\n",
      "Epoch 38/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.4741 - accuracy: 0.8285 - val_loss: 0.3909 - val_accuracy: 0.8811\n",
      "Epoch 39/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.4538 - accuracy: 0.8417 - val_loss: 0.4228 - val_accuracy: 0.8620\n",
      "Epoch 40/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.4387 - accuracy: 0.8433 - val_loss: 0.3600 - val_accuracy: 0.8885\n",
      "Epoch 41/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.4200 - accuracy: 0.8500 - val_loss: 0.3713 - val_accuracy: 0.8949\n",
      "Epoch 42/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.3972 - accuracy: 0.8643 - val_loss: 0.3352 - val_accuracy: 0.8970\n",
      "Epoch 43/100\n",
      "3766/3766 [==============================] - 32s 8ms/sample - loss: 0.3846 - accuracy: 0.8635 - val_loss: 0.3112 - val_accuracy: 0.9119\n",
      "Epoch 44/100\n",
      "3766/3766 [==============================] - 32s 8ms/sample - loss: 0.3782 - accuracy: 0.8712 - val_loss: 0.3740 - val_accuracy: 0.8779\n",
      "Epoch 45/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.3517 - accuracy: 0.8781 - val_loss: 0.2856 - val_accuracy: 0.9130\n",
      "Epoch 46/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.3497 - accuracy: 0.8861 - val_loss: 0.2842 - val_accuracy: 0.9087\n",
      "Epoch 47/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.3316 - accuracy: 0.8882 - val_loss: 0.2867 - val_accuracy: 0.9098\n",
      "Epoch 48/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.3132 - accuracy: 0.8914 - val_loss: 0.2676 - val_accuracy: 0.9140\n",
      "Epoch 49/100\n",
      "3766/3766 [==============================] - 36s 9ms/sample - loss: 0.2943 - accuracy: 0.8994 - val_loss: 0.2437 - val_accuracy: 0.9246\n",
      "Epoch 50/100\n",
      "3766/3766 [==============================] - 34s 9ms/sample - loss: 0.3037 - accuracy: 0.8959 - val_loss: 0.2394 - val_accuracy: 0.9289\n",
      "Epoch 51/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.2958 - accuracy: 0.8962 - val_loss: 0.2272 - val_accuracy: 0.9246\n",
      "Epoch 52/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.2699 - accuracy: 0.9108 - val_loss: 0.2762 - val_accuracy: 0.9023\n",
      "Epoch 53/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.2696 - accuracy: 0.9110 - val_loss: 0.2055 - val_accuracy: 0.9342\n",
      "Epoch 54/100\n",
      "3766/3766 [==============================] - 35s 9ms/sample - loss: 0.2528 - accuracy: 0.9150 - val_loss: 0.2230 - val_accuracy: 0.9374\n",
      "Epoch 55/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.2465 - accuracy: 0.9187 - val_loss: 0.2161 - val_accuracy: 0.9289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "3766/3766 [==============================] - 32s 8ms/sample - loss: 0.2427 - accuracy: 0.9153 - val_loss: 0.1968 - val_accuracy: 0.9352\n",
      "Epoch 57/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.2365 - accuracy: 0.9187 - val_loss: 0.1819 - val_accuracy: 0.9406\n",
      "Epoch 58/100\n",
      "3766/3766 [==============================] - 40s 11ms/sample - loss: 0.2244 - accuracy: 0.9251 - val_loss: 0.1808 - val_accuracy: 0.9416\n",
      "Epoch 59/100\n",
      "3766/3766 [==============================] - 45s 12ms/sample - loss: 0.2227 - accuracy: 0.9267 - val_loss: 0.1996 - val_accuracy: 0.9352\n",
      "Epoch 60/100\n",
      "3766/3766 [==============================] - 40s 11ms/sample - loss: 0.2085 - accuracy: 0.9302 - val_loss: 0.1711 - val_accuracy: 0.9448\n",
      "Epoch 61/100\n",
      "3766/3766 [==============================] - 40s 11ms/sample - loss: 0.2144 - accuracy: 0.9315 - val_loss: 0.1716 - val_accuracy: 0.9448\n",
      "Epoch 62/100\n",
      "3766/3766 [==============================] - 47s 12ms/sample - loss: 0.1963 - accuracy: 0.9349 - val_loss: 0.1597 - val_accuracy: 0.9544\n",
      "Epoch 63/100\n",
      "3766/3766 [==============================] - 38s 10ms/sample - loss: 0.1971 - accuracy: 0.9334 - val_loss: 0.1586 - val_accuracy: 0.9501\n",
      "Epoch 64/100\n",
      "3766/3766 [==============================] - 32s 8ms/sample - loss: 0.1800 - accuracy: 0.9403 - val_loss: 0.1545 - val_accuracy: 0.9512\n",
      "Epoch 65/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.1834 - accuracy: 0.9403 - val_loss: 0.1902 - val_accuracy: 0.9352\n",
      "Epoch 66/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.1762 - accuracy: 0.9445 - val_loss: 0.1540 - val_accuracy: 0.9469\n",
      "Epoch 67/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.1635 - accuracy: 0.9493 - val_loss: 0.1380 - val_accuracy: 0.9586\n",
      "Epoch 68/100\n",
      "3766/3766 [==============================] - 32s 8ms/sample - loss: 0.1752 - accuracy: 0.9413 - val_loss: 0.1542 - val_accuracy: 0.9554\n",
      "Epoch 69/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.1567 - accuracy: 0.9519 - val_loss: 0.1391 - val_accuracy: 0.9522\n",
      "Epoch 70/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.1493 - accuracy: 0.9490 - val_loss: 0.1338 - val_accuracy: 0.9575\n",
      "Epoch 71/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.1589 - accuracy: 0.9498 - val_loss: 0.1329 - val_accuracy: 0.9575\n",
      "Epoch 72/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.1366 - accuracy: 0.9551 - val_loss: 0.1319 - val_accuracy: 0.9533\n",
      "Epoch 73/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.1422 - accuracy: 0.9578 - val_loss: 0.1375 - val_accuracy: 0.9501\n",
      "Epoch 74/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.1382 - accuracy: 0.9580 - val_loss: 0.1251 - val_accuracy: 0.9586\n",
      "Epoch 75/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.1325 - accuracy: 0.9596 - val_loss: 0.1182 - val_accuracy: 0.9575\n",
      "Epoch 76/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.1296 - accuracy: 0.9612 - val_loss: 0.1245 - val_accuracy: 0.9575\n",
      "Epoch 77/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.1231 - accuracy: 0.9612 - val_loss: 0.1211 - val_accuracy: 0.9597\n",
      "Epoch 78/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.1203 - accuracy: 0.9631 - val_loss: 0.1410 - val_accuracy: 0.9437\n",
      "Epoch 79/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.1161 - accuracy: 0.9618 - val_loss: 0.1209 - val_accuracy: 0.9586\n",
      "Epoch 80/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.1155 - accuracy: 0.9642 - val_loss: 0.1118 - val_accuracy: 0.9597\n",
      "Epoch 81/100\n",
      "3766/3766 [==============================] - 32s 8ms/sample - loss: 0.1032 - accuracy: 0.9705 - val_loss: 0.1185 - val_accuracy: 0.9607\n",
      "Epoch 82/100\n",
      "3766/3766 [==============================] - 32s 8ms/sample - loss: 0.1155 - accuracy: 0.9588 - val_loss: 0.1181 - val_accuracy: 0.9597\n",
      "Epoch 83/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.1139 - accuracy: 0.9634 - val_loss: 0.1140 - val_accuracy: 0.9607\n",
      "Epoch 84/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.1110 - accuracy: 0.9644 - val_loss: 0.1155 - val_accuracy: 0.9597\n",
      "Epoch 85/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.1027 - accuracy: 0.9689 - val_loss: 0.1158 - val_accuracy: 0.9586\n",
      "Epoch 86/100\n",
      "3766/3766 [==============================] - 32s 8ms/sample - loss: 0.1053 - accuracy: 0.9657 - val_loss: 0.1014 - val_accuracy: 0.9607\n",
      "Epoch 87/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.0980 - accuracy: 0.9713 - val_loss: 0.1467 - val_accuracy: 0.9427\n",
      "Epoch 88/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.0950 - accuracy: 0.9676 - val_loss: 0.1009 - val_accuracy: 0.9618\n",
      "Epoch 89/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.0908 - accuracy: 0.9716 - val_loss: 0.0977 - val_accuracy: 0.9618\n",
      "Epoch 90/100\n",
      "3766/3766 [==============================] - 35s 9ms/sample - loss: 0.0939 - accuracy: 0.9705 - val_loss: 0.1057 - val_accuracy: 0.9628\n",
      "Epoch 91/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.0879 - accuracy: 0.9732 - val_loss: 0.0994 - val_accuracy: 0.9607\n",
      "Epoch 92/100\n",
      "3766/3766 [==============================] - 32s 9ms/sample - loss: 0.0855 - accuracy: 0.9742 - val_loss: 0.1030 - val_accuracy: 0.9682\n",
      "Epoch 93/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.0804 - accuracy: 0.9758 - val_loss: 0.1001 - val_accuracy: 0.9660\n",
      "Epoch 94/100\n",
      "3766/3766 [==============================] - 34s 9ms/sample - loss: 0.0825 - accuracy: 0.9780 - val_loss: 0.1049 - val_accuracy: 0.9650\n",
      "Epoch 95/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.0821 - accuracy: 0.9748 - val_loss: 0.0954 - val_accuracy: 0.9650\n",
      "Epoch 96/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.0843 - accuracy: 0.9756 - val_loss: 0.0941 - val_accuracy: 0.9639\n",
      "Epoch 97/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.0717 - accuracy: 0.9790 - val_loss: 0.1038 - val_accuracy: 0.9597\n",
      "Epoch 98/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.0767 - accuracy: 0.9766 - val_loss: 0.1085 - val_accuracy: 0.9618\n",
      "Epoch 99/100\n",
      "3766/3766 [==============================] - 33s 9ms/sample - loss: 0.0758 - accuracy: 0.9742 - val_loss: 0.0947 - val_accuracy: 0.9628\n",
      "Epoch 100/100\n",
      "3766/3766 [==============================] - 34s 9ms/sample - loss: 0.0696 - accuracy: 0.9827 - val_loss: 0.0936 - val_accuracy: 0.9682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16529ee48>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Model\n",
    "\n",
    "\n",
    "# Set the model type as sequential \n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(34, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", input_shape=input_shape))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(34, (3, 3), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(45, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(.45))\n",
    "model.add(tf.keras.layers.Dense(len(CATEGORIES), activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.SGD(lr=0.02),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(np.array(X_train), np.array(y_train),\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data=(np.array(X_test), np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# function to parse single image\n",
    "def load_image(image_path):\n",
    "   img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "   img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "   img = np.asarray(img)\n",
    "   #normalize image\n",
    "   img = tf.keras.utils.normalize(img, axis=1)\n",
    "   #reshape into tensor\n",
    "   img = img.reshape(1, IMG_WIDTH, IMG_HEIGHT, 1)\n",
    "   return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test model with selected image\n",
    "rock = \"rockpaperscissors/rock/tGBAO9oyBYRD7XXS.png\"\n",
    "paper = \"rockpaperscissors/paper/tiS1ECooPwR5IvFK.png\"\n",
    "scissors = \"rockpaperscissors/scissors/pZ9zE5ahoKZhIZqm.png\"\n",
    "catagories = ['paper', 'rock', 'scissors']\n",
    "test_img = [rock, paper, scissors]\n",
    "selector = 0\n",
    "prediction = classifier.predict_classes(load_image(test_img[selector]))\n",
    "plt.imshow(cv2.imread(test_img[x]))\n",
    "print(\"predicted action is\", catagories[prediction[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
